{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/ymoslem/OpenNMT-Tutorial/blob/main/2-NMT-Training.ipynb","timestamp":1701269232830}],"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"vSUyCs23M_H2","executionInfo":{"status":"ok","timestamp":1701526359437,"user_tz":-420,"elapsed":6809,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}},"outputId":"52fb8d3f-35db-4431-9bbf-8f0d9778875a","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Install OpenNMT-py 3.x\n","!pip3 install OpenNMT-py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: OpenNMT-py in /usr/local/lib/python3.10/dist-packages (3.4.3)\n","Requirement already satisfied: torch<2.2,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.1.0+cu118)\n","Requirement already satisfied: configargparse in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.7)\n","Requirement already satisfied: ctranslate2<4,>=3.17 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.22.0)\n","Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.14.1)\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.2.5)\n","Requirement already satisfied: waitress in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.1.2)\n","Requirement already satisfied: pyonmttok<2,>=1.35 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.37.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (6.0.1)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.3.3)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.5.2)\n","Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.0.0)\n","Requirement already satisfied: fasttext-wheel in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (0.9.2)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.6.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->OpenNMT-py) (67.7.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->OpenNMT-py) (1.23.5)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.59.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.5.1)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (2.1.0)\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel->OpenNMT-py) (2.11.1)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (8.1.7)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (2.8.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (2023.6.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (0.4.6)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (4.9.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.10.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (4.66.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.10.13)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.2,>=2.0.1->OpenNMT-py) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2023.11.17)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->OpenNMT-py) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->OpenNMT-py) (0.1.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.2,>=2.0.1->OpenNMT-py) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->OpenNMT-py) (3.2.2)\n"]}]},{"cell_type":"markdown","source":["# Prepare Your Datasets\n"],"metadata":{"id":"vhgIdJn-cLqu"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"e-7c2qc5WBzy","executionInfo":{"status":"ok","timestamp":1701526125178,"user_tz":-420,"elapsed":21405,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}},"outputId":"7b1ae5d7-35df-4770-d86e-f4d1cf6ada10","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"dWVOWYedzZ_G","executionInfo":{"status":"ok","timestamp":1701526269370,"user_tz":-420,"elapsed":423,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}},"outputId":"008122a4-bb48-40be-e1b0-f82833135e22","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Open the folder where you saved your prepapred datasets from the processing step\n","%cd /content/drive/MyDrive/nmt/\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/nmt\n","compute-bleu.py\t\t\t\t      merged.vi-filtered.vi.subword.train\n","config.yaml\t\t\t\t      model_released.pt\n","merged.source\t\t\t\t      models\n","merged.source-filtered.source\t\t      MT-Preparation\n","merged.source-filtered.source.subword\t      README\n","merged.source-filtered.source.subword.dev     run\n","merged.source-filtered.source.subword.test    source.model\n","merged.source-filtered.source.subword.train   source.vocab\n","merged.vi\t\t\t\t      target.model\n","merged.vi-filtered.vi\t\t\t      target.vocab\n","merged.vi-filtered.vi.subword\t\t      test.translated\n","merged.vi-filtered.vi.subword.dev\t      test.translated.desubword\n","merged.vi-filtered.vi.subword.test\t      train.log\n","merged.vi-filtered.vi.subword.test.desubword\n"]}]},{"cell_type":"markdown","metadata":{"id":"MPlmhd426B7l"},"source":["# Create the Training Configuration File\n","\n","The following config file matches most of the recommended values for the Transformer model [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762). As the current dataset is small, we reduced the following values:\n","* `train_steps` - for datasets with a few millions of sentences, consider using a value between 100000 and 200000, or more! Enabling the option `early_stopping` can help stop the training when there is no considerable improvement.\n","* `valid_steps` - 10000 can be good if the value `train_steps` is big enough.\n","* `warmup_steps` - obviously, its value must be less than `train_steps`. Try 4000 and 8000 values."]},{"cell_type":"code","metadata":{"id":"qbW7Xek6UDlY"},"source":["# Create the YAML configuration file\n","\n","config = '''# config.yaml\n","\n","\n","## Where the samples will be written\n","save_data: run\n","\n","# Training files\n","data:\n","    corpus_1:\n","        path_src: merged.source-filtered.source.subword.train\n","        path_tgt: merged.vi-filtered.vi.subword.train\n","        transforms: [filtertoolong]\n","    valid:\n","        path_src: merged.source-filtered.source.subword.dev\n","        path_tgt: merged.vi-filtered.vi.subword.dev\n","        transforms: [filtertoolong]\n","\n","# Vocabulary files, generated by onmt_build_vocab\n","src_vocab: run/source.vocab\n","tgt_vocab: run/target.vocab\n","\n","# Vocabulary size - should be the same as in sentence piece\n","src_vocab_size: 150000\n","tgt_vocab_size: 50000\n","\n","# Filter out source/target longer than n if [filtertoolong] enabled\n","src_seq_length: 150\n","src_seq_length: 150\n","\n","# Tokenization options\n","src_subword_model: source.model\n","tgt_subword_model: target.model\n","\n","# Where to save the log file and the output models/checkpoints\n","log_file: train.log\n","save_model: models/model.enfrde\n","\n","# Stop training if it does not improve after n validations\n","early_stopping: 4\n","\n","# Default: 5000 - Save a model checkpoint for each n\n","save_checkpoint_steps: 1000\n","\n","# To save space, limit checkpoints to last n\n","# keep_checkpoint: 3\n","\n","seed: 3435\n","\n","# Default: 100000 - Train the model to max n steps\n","# Increase to 200000 or more for large datasets\n","# For fine-tuning, add up the required steps to the original steps\n","train_steps: 20000\n","\n","# Default: 10000 - Run validation after n steps\n","valid_steps: 1000\n","\n","# Default: 4000 - for large datasets, try up to 8000\n","warmup_steps: 1000\n","report_every: 100\n","\n","# Number of GPUs, and IDs of GPUs\n","world_size: 1\n","gpu_ranks: [0]\n","\n","# Batching\n","bucket_size: 262144\n","num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n","batch_type: \"tokens\"\n","batch_size: 8192   # Tokens per batch, change when CUDA out of memory\n","valid_batch_size: 4096\n","max_generator_batches: 2\n","accum_count: [4]\n","accum_steps: [0]\n","\n","# Optimization\n","model_dtype: \"fp16\"\n","optim: \"adam\"\n","learning_rate: 2\n","# warmup_steps: 8000\n","decay_method: \"noam\"\n","adam_beta2: 0.998\n","max_grad_norm: 0\n","label_smoothing: 0.1\n","param_init: 0\n","param_init_glorot: true\n","normalization: \"tokens\"\n","\n","# Model\n","encoder_type: transformer\n","decoder_type: transformer\n","position_encoding: true\n","enc_layers: 6\n","dec_layers: 6\n","heads: 8\n","hidden_size: 512\n","word_vec_size: 512\n","transformer_ff: 2048\n","dropout_steps: [0]\n","dropout: [0.1]\n","attention_dropout: [0.1]\n","'''\n","\n","with open(\"config.yaml\", \"w+\") as config_yaml:\n","  config_yaml.write(config)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F0bcqYkEXhRY"},"source":["# Build Vocabulary\n","\n","For large datasets, it is not feasable to use all words/tokens found in the corpus. Instead, a specific set of vocabulary is extracted from the training dataset, usually betweeen 32k and 100k words. This is the main purpose of the vocabulary building step."]},{"cell_type":"code","metadata":{"id":"AuwltKp_VhnQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9a3cffa9-d3d0-4515-8c11-426bb36a5095","executionInfo":{"status":"ok","timestamp":1701427140023,"user_tz":-420,"elapsed":3,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}}},"source":["# Find the number of CPUs/cores on the machine\n","!nproc --all"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}]},{"cell_type":"code","metadata":{"id":"P2GV1PgyUsJr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6b961c6-dd8f-4cab-a20c-bde246afcf70","executionInfo":{"status":"ok","timestamp":1701409310491,"user_tz":-420,"elapsed":47793,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}}},"source":["# Build Vocabulary\n","\n","# -config: path to your config.yaml file\n","# -n_sample: use -1 to build vocabulary on all the segment in the training dataset\n","# -num_threads: change it to match the number of CPUs to run it faster\n","\n","!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-01 05:41:05.769306: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-01 05:41:05.769360: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-01 05:41:05.769402: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-01 05:41:05.777254: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-01 05:41:06.934076: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-12-01 05:41:08.437972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-01 05:41:08.438375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-01 05:41:08.438536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-12-01 05:41:08,892 INFO] Counter vocab from -1 samples.\n","[2023-12-01 05:41:08,892 INFO] n_sample=-1: Build vocab on full datasets.\n","[2023-12-01 05:41:48,095 INFO] * Transform statistics for corpus_1(50.00%):\n","\t\t\t* FilterTooLongStats(filtered=112)\n","\n","[2023-12-01 05:41:48,580 INFO] * Transform statistics for corpus_1(50.00%):\n","\t\t\t* FilterTooLongStats(filtered=117)\n","\n","[2023-12-01 05:41:48,910 INFO] Counters src: 149904\n","[2023-12-01 05:41:48,910 INFO] Counters tgt: 30168\n"]}]},{"cell_type":"markdown","metadata":{"id":"ncWyNtxiO_Ov"},"source":["From the **Runtime menu** > **Change runtime type**, make sure that the \"**Hardware accelerator**\" is \"**GPU**\".\n"]},{"cell_type":"code","metadata":{"id":"TMMPeS-pSV8I","colab":{"base_uri":"https://localhost:8080/"},"outputId":"664dfecb-e90d-4d9b-a911-fa88446cff45","executionInfo":{"status":"ok","timestamp":1701409362996,"user_tz":-420,"elapsed":475,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}}},"source":["# Check if the GPU is active\n","!nvidia-smi -L"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-23c970b2-6d3f-928a-7bea-458ceaa39ad0)\n"]}]},{"cell_type":"code","metadata":{"id":"_3rVQhd4NXNG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9a31c99c-2f44-429a-c332-86e6deda7f76","executionInfo":{"status":"ok","timestamp":1701409370369,"user_tz":-420,"elapsed":2042,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}}},"source":["# Check if the GPU is visable to PyTorch\n","\n","import torch\n","\n","print(torch.cuda.is_available())\n","print(torch.cuda.get_device_name(0))\n","\n","gpu_memory = torch.cuda.mem_get_info(0)\n","print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","Tesla V100-SXM2-16GB\n","Free GPU memory: 15842.125 out of: 16150.875\n"]}]},{"cell_type":"markdown","metadata":{"id":"8aCxETSnXcL-"},"source":["# Training\n"]},{"cell_type":"code","source":["!rm -rf drive/MyDrive/nmt/models/"],"metadata":{"id":"HZd1o1kIb6Nv"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"prJCKA2CP-dl","executionInfo":{"status":"ok","timestamp":1701411413787,"user_tz":-420,"elapsed":2034714,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}},"outputId":"2f61dc5c-fffc-4114-c21c-3a2ec1ada529","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Train the NMT model\n","!onmt_train -config config.yaml"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-01 05:43:02.330533: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-01 05:43:02.330590: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-01 05:43:02.330632: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-01 05:43:02.338998: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-01 05:43:03.481948: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-12-01 05:43:04.969490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-01 05:43:04.969915: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-01 05:43:04.970083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","[2023-12-01 05:43:05,695 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-12-01 05:43:05,696 INFO] Parsed 2 corpora from -data.\n","[2023-12-01 05:43:05,697 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n","[2023-12-01 05:43:06,095 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', ',', '.', \"'\", '▁the', '▁de', '▁']\n","[2023-12-01 05:43:06,095 INFO] The decoder start token is: <s>\n","[2023-12-01 05:43:06,095 INFO] Building model...\n","[2023-12-01 05:43:08,240 INFO] Switching model to float32 for amp/apex_amp\n","[2023-12-01 05:43:08,240 INFO] Non quantized layer compute is fp16\n","[2023-12-01 05:43:08,533 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(149912, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): ModuleList(\n","      (0-5): 6 x TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(30176, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","    (transformer_layers): ModuleList(\n","      (0-5): 6 x TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (generator): Linear(in_features=512, out_features=30176, bias=True)\n",")\n","[2023-12-01 05:43:08,537 INFO] encoder: 95642624\n","[2023-12-01 05:43:08,537 INFO] decoder: 56115680\n","[2023-12-01 05:43:08,537 INFO] * number of parameters: 151758304\n","[2023-12-01 05:43:08,538 INFO] Trainable parameters = {'torch.float32': 151758304, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-12-01 05:43:08,538 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-12-01 05:43:08,538 INFO]  * src vocab size = 149912\n","[2023-12-01 05:43:08,538 INFO]  * tgt vocab size = 30176\n","[2023-12-01 05:43:08,912 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2023-12-01 05:43:08,913 INFO] Starting training on GPU: [0]\n","[2023-12-01 05:43:08,913 INFO] Start training loop and validate every 1000 steps...\n","[2023-12-01 05:43:08,913 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n","[2023-12-01 05:44:26,675 INFO] Step 100/ 3000; acc: 5.0; ppl: 4171.2; xent: 8.3; lr: 0.00028; sents:  107534; bsz: 6142/7303/269; 31593/37568 tok/s;     78 sec;\n","[2023-12-01 05:45:15,752 INFO] Step 200/ 3000; acc: 12.1; ppl: 680.9; xent: 6.5; lr: 0.00056; sents:  112374; bsz: 6183/7345/281; 50394/59866 tok/s;    127 sec;\n","[2023-12-01 05:46:40,991 INFO] Step 300/ 3000; acc: 22.7; ppl: 255.5; xent: 5.5; lr: 0.00084; sents:  104635; bsz: 6174/7316/262; 28974/34332 tok/s;    212 sec;\n","[2023-12-01 05:47:30,717 INFO] Step 400/ 3000; acc: 28.2; ppl: 154.9; xent: 5.0; lr: 0.00112; sents:  112867; bsz: 6158/7320/282; 49540/58881 tok/s;    262 sec;\n","[2023-12-01 05:48:20,868 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=173)\n","\n","[2023-12-01 05:48:20,869 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 2\n","[2023-12-01 05:48:54,161 INFO] Step 500/ 3000; acc: 32.6; ppl: 114.2; xent: 4.7; lr: 0.00140; sents:  108324; bsz: 6122/7362/271; 29349/35293 tok/s;    345 sec;\n","[2023-12-01 05:49:43,418 INFO] Step 600/ 3000; acc: 36.9; ppl:  86.6; xent: 4.5; lr: 0.00168; sents:  107678; bsz: 6190/7344/269; 50266/59637 tok/s;    395 sec;\n","[2023-12-01 05:50:33,029 INFO] Step 700/ 3000; acc: 40.4; ppl:  68.9; xent: 4.2; lr: 0.00196; sents:  112203; bsz: 6190/7349/281; 49910/59255 tok/s;    444 sec;\n","[2023-12-01 05:51:56,972 INFO] Step 800/ 3000; acc: 42.6; ppl:  59.2; xent: 4.1; lr: 0.00224; sents:  111236; bsz: 6205/7389/278; 29568/35209 tok/s;    528 sec;\n","[2023-12-01 05:52:46,788 INFO] Step 900/ 3000; acc: 44.2; ppl:  53.7; xent: 4.0; lr: 0.00252; sents:  111758; bsz: 6226/7359/279; 49992/59089 tok/s;    578 sec;\n","[2023-12-01 05:54:11,075 INFO] Step 1000/ 3000; acc: 45.3; ppl:  49.5; xent: 3.9; lr: 0.00279; sents:  104723; bsz: 6062/7311/262; 28770/34696 tok/s;    662 sec;\n","[2023-12-01 05:54:12,509 INFO] valid stats calculation\n","                           took: 1.4326536655426025 s.\n","[2023-12-01 05:54:12,510 INFO] Train perplexity: 161.076\n","[2023-12-01 05:54:12,510 INFO] Train accuracy: 31.0264\n","[2023-12-01 05:54:12,510 INFO] Sentences processed: 1.09333e+06\n","[2023-12-01 05:54:12,510 INFO] Average bsz: 6165/7340/273\n","[2023-12-01 05:54:12,510 INFO] Validation perplexity: 44.3588\n","[2023-12-01 05:54:12,510 INFO] Validation accuracy: 47.5959\n","[2023-12-01 05:54:12,511 INFO] Model is improving ppl: inf --> 44.3588.\n","[2023-12-01 05:54:12,511 INFO] Model is improving acc: -inf --> 47.5959.\n","[2023-12-01 05:54:12,539 INFO] Saving checkpoint models/model.enfrde_step_1000.pt\n","[2023-12-01 05:55:15,495 INFO] Step 1100/ 3000; acc: 46.7; ppl:  45.3; xent: 3.8; lr: 0.00266; sents:  110286; bsz: 6231/7344/276; 38688/45600 tok/s;    727 sec;\n","[2023-12-01 05:56:12,499 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=242)\n","\n","[2023-12-01 05:56:12,499 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 3\n","[2023-12-01 05:56:44,692 INFO] Step 1200/ 3000; acc: 48.2; ppl:  41.1; xent: 3.7; lr: 0.00255; sents:  109994; bsz: 6203/7368/275; 27817/33041 tok/s;    816 sec;\n","[2023-12-01 05:57:35,162 INFO] Step 1300/ 3000; acc: 49.5; ppl:  37.4; xent: 3.6; lr: 0.00245; sents:  107942; bsz: 6122/7282/270; 48524/57714 tok/s;    866 sec;\n","[2023-12-01 05:58:25,831 INFO] Step 1400/ 3000; acc: 50.9; ppl:  34.5; xent: 3.5; lr: 0.00236; sents:  109135; bsz: 6197/7343/273; 48919/57968 tok/s;    917 sec;\n","[2023-12-01 05:59:52,900 INFO] Step 1500/ 3000; acc: 52.1; ppl:  31.8; xent: 3.5; lr: 0.00228; sents:  111818; bsz: 6237/7425/280; 28654/34110 tok/s;   1004 sec;\n","[2023-12-01 06:00:44,292 INFO] Step 1600/ 3000; acc: 53.1; ppl:  30.0; xent: 3.4; lr: 0.00221; sents:  113032; bsz: 6177/7400/283; 48080/57594 tok/s;   1055 sec;\n","[2023-12-01 06:02:11,594 INFO] Step 1700/ 3000; acc: 53.2; ppl:  29.6; xent: 3.4; lr: 0.00214; sents:  106145; bsz: 6143/7264/265; 28146/33283 tok/s;   1143 sec;\n","[2023-12-01 06:03:01,506 INFO] Step 1800/ 3000; acc: 54.1; ppl:  27.9; xent: 3.3; lr: 0.00208; sents:  106877; bsz: 6204/7354/267; 49722/58937 tok/s;   1193 sec;\n","[2023-12-01 06:03:51,476 INFO] Step 1900/ 3000; acc: 54.7; ppl:  27.0; xent: 3.3; lr: 0.00203; sents:  108324; bsz: 6165/7326/271; 49350/58643 tok/s;   1243 sec;\n","[2023-12-01 06:04:01,535 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=248)\n","\n","[2023-12-01 06:04:01,535 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 4\n","[2023-12-01 06:05:19,960 INFO] Step 2000/ 3000; acc: 55.8; ppl:  25.2; xent: 3.2; lr: 0.00198; sents:  116856; bsz: 6188/7339/292; 27972/33176 tok/s;   1331 sec;\n","[2023-12-01 06:05:20,814 INFO] valid stats calculation\n","                           took: 0.8519434928894043 s.\n","[2023-12-01 06:05:20,815 INFO] Train perplexity: 72.275\n","[2023-12-01 06:05:20,815 INFO] Train accuracy: 41.4243\n","[2023-12-01 06:05:20,816 INFO] Sentences processed: 2.19374e+06\n","[2023-12-01 06:05:20,816 INFO] Average bsz: 6176/7342/274\n","[2023-12-01 06:05:20,816 INFO] Validation perplexity: 26.4902\n","[2023-12-01 06:05:20,816 INFO] Validation accuracy: 55.6878\n","[2023-12-01 06:05:20,816 INFO] Model is improving ppl: 44.3588 --> 26.4902.\n","[2023-12-01 06:05:20,816 INFO] Model is improving acc: 47.5959 --> 55.6878.\n","[2023-12-01 06:05:20,847 INFO] Saving checkpoint models/model.enfrde_step_2000.pt\n","[2023-12-01 06:06:26,132 INFO] Step 2100/ 3000; acc: 55.8; ppl:  25.2; xent: 3.2; lr: 0.00193; sents:  103018; bsz: 6170/7438/258; 37296/44964 tok/s;   1397 sec;\n","[2023-12-01 06:07:54,244 INFO] Step 2200/ 3000; acc: 56.0; ppl:  24.7; xent: 3.2; lr: 0.00188; sents:  105028; bsz: 6296/7351/263; 28582/33373 tok/s;   1485 sec;\n","[2023-12-01 06:08:45,029 INFO] Step 2300/ 3000; acc: 57.1; ppl:  23.3; xent: 3.1; lr: 0.00184; sents:  113137; bsz: 6107/7287/283; 48097/57393 tok/s;   1536 sec;\n","[2023-12-01 06:10:13,501 INFO] Step 2400/ 3000; acc: 57.3; ppl:  23.0; xent: 3.1; lr: 0.00180; sents:  111348; bsz: 6125/7355/278; 27693/33253 tok/s;   1625 sec;\n","[2023-12-01 06:11:04,143 INFO] Step 2500/ 3000; acc: 57.7; ppl:  22.3; xent: 3.1; lr: 0.00177; sents:  109044; bsz: 6191/7304/273; 48902/57689 tok/s;   1675 sec;\n","[2023-12-01 06:11:54,996 INFO] Step 2600/ 3000; acc: 58.0; ppl:  22.1; xent: 3.1; lr: 0.00173; sents:  108060; bsz: 6180/7380/270; 48614/58046 tok/s;   1726 sec;\n","[2023-12-01 06:12:12,000 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=248)\n","\n","[2023-12-01 06:12:12,001 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 5\n","[2023-12-01 06:13:23,182 INFO] Step 2700/ 3000; acc: 58.5; ppl:  21.4; xent: 3.1; lr: 0.00170; sents:  111975; bsz: 6113/7254/280; 27726/32902 tok/s;   1814 sec;\n","[2023-12-01 06:14:14,212 INFO] Step 2800/ 3000; acc: 58.9; ppl:  20.9; xent: 3.0; lr: 0.00167; sents:  111438; bsz: 6222/7341/279; 48772/57542 tok/s;   1865 sec;\n","[2023-12-01 06:15:42,164 INFO] Step 2900/ 3000; acc: 59.2; ppl:  20.6; xent: 3.0; lr: 0.00164; sents:  103691; bsz: 6145/7388/259; 27947/33599 tok/s;   1953 sec;\n","[2023-12-01 06:16:32,950 INFO] Step 3000/ 3000; acc: 60.0; ppl:  19.7; xent: 3.0; lr: 0.00161; sents:  108868; bsz: 6237/7425/272; 49125/58481 tok/s;   2004 sec;\n","[2023-12-01 06:16:33,814 INFO] valid stats calculation\n","                           took: 0.8625173568725586 s.\n","[2023-12-01 06:16:33,815 INFO] Train perplexity: 48.7886\n","[2023-12-01 06:16:33,815 INFO] Train accuracy: 46.9032\n","[2023-12-01 06:16:33,815 INFO] Sentences processed: 3.27935e+06\n","[2023-12-01 06:16:33,815 INFO] Average bsz: 6177/7345/273\n","[2023-12-01 06:16:33,815 INFO] Validation perplexity: 22.3983\n","[2023-12-01 06:16:33,815 INFO] Validation accuracy: 58.5239\n","[2023-12-01 06:16:33,815 INFO] Model is improving ppl: 26.4902 --> 22.3983.\n","[2023-12-01 06:16:33,816 INFO] Model is improving acc: 55.6878 --> 58.5239.\n","[2023-12-01 06:16:33,844 INFO] Saving checkpoint models/model.enfrde_step_3000.pt\n"]}]},{"cell_type":"code","source":["# For error debugging try:\n","# !dmesg -T"],"metadata":{"id":"XUYAvE8ffK2k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!onmt_train -config config.yaml -train_from models/model.enfrde_step_3000.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_KGM-29f-n7e","outputId":"923de716-1510-4de8-ab99-10c4b5e084bd","executionInfo":{"status":"ok","timestamp":1701432640883,"user_tz":-420,"elapsed":5473484,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-01 10:39:33.687015: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-01 10:39:33.687099: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-01 10:39:33.687143: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-01 10:39:33.695406: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-01 10:39:34.851396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-12-01 10:39:36.342830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-01 10:39:36.343310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-01 10:39:36.343503: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","[2023-12-01 10:39:37,640 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2023-12-01 10:39:38,061 INFO] Parsed 2 corpora from -data.\n","[2023-12-01 10:39:38,061 INFO] Loading checkpoint from models/model.enfrde_step_12000.pt\n","[2023-12-01 10:39:54,587 INFO] Building model...\n","[2023-12-01 10:39:56,496 INFO] Switching model to float32 for amp/apex_amp\n","[2023-12-01 10:39:56,496 INFO] Non quantized layer compute is fp16\n","[2023-12-01 10:40:04,778 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(149912, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): ModuleList(\n","      (0-5): 6 x TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(30176, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding()\n","      )\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","    (transformer_layers): ModuleList(\n","      (0-5): 6 x TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.1, inplace=False)\n","          (dropout_2): Dropout(p=0.1, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n","        )\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (generator): Linear(in_features=512, out_features=30176, bias=True)\n",")\n","[2023-12-01 10:40:04,781 INFO] encoder: 95642624\n","[2023-12-01 10:40:04,781 INFO] decoder: 56115680\n","[2023-12-01 10:40:04,781 INFO] * number of parameters: 151758304\n","[2023-12-01 10:40:04,783 INFO] Trainable parameters = {'torch.float32': 151758304, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-12-01 10:40:04,784 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n","[2023-12-01 10:40:04,784 INFO]  * src vocab size = 149912\n","[2023-12-01 10:40:04,784 INFO]  * tgt vocab size = 30176\n","[2023-12-01 10:40:05,539 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 1\n","[2023-12-01 10:40:05,539 INFO] Starting training on GPU: [0]\n","[2023-12-01 10:40:05,539 INFO] Start training loop and validate every 1000 steps...\n","[2023-12-01 10:40:05,540 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n","[2023-12-01 10:41:27,430 INFO] Step 12100/20000; acc: 79.9; ppl:   8.3; xent: 2.1; lr: 0.00080; sents:  107534; bsz: 6142/7303/269; 30001/35675 tok/s;     82 sec;\n","[2023-12-01 10:42:16,868 INFO] Step 12200/20000; acc: 80.0; ppl:   8.3; xent: 2.1; lr: 0.00080; sents:  112374; bsz: 6183/7345/281; 50025/59429 tok/s;    131 sec;\n","[2023-12-01 10:43:44,929 INFO] Step 12300/20000; acc: 79.5; ppl:   8.4; xent: 2.1; lr: 0.00080; sents:  104635; bsz: 6174/7316/262; 28046/33232 tok/s;    219 sec;\n","[2023-12-01 10:44:34,792 INFO] Step 12400/20000; acc: 79.2; ppl:   8.5; xent: 2.1; lr: 0.00079; sents:  112867; bsz: 6158/7320/282; 49404/58720 tok/s;    269 sec;\n","[2023-12-01 10:45:25,387 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=173)\n","\n","[2023-12-01 10:45:25,387 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 2\n","[2023-12-01 10:45:58,834 INFO] Step 12500/20000; acc: 79.0; ppl:   8.6; xent: 2.1; lr: 0.00079; sents:  108324; bsz: 6122/7362/271; 29140/35042 tok/s;    353 sec;\n","[2023-12-01 10:46:48,868 INFO] Step 12600/20000; acc: 79.1; ppl:   8.6; xent: 2.1; lr: 0.00079; sents:  107678; bsz: 6190/7344/269; 49485/58711 tok/s;    403 sec;\n","[2023-12-01 10:47:39,574 INFO] Step 12700/20000; acc: 78.8; ppl:   8.7; xent: 2.2; lr: 0.00078; sents:  112203; bsz: 6190/7349/281; 48832/57975 tok/s;    454 sec;\n","[2023-12-01 10:49:06,251 INFO] Step 12800/20000; acc: 80.3; ppl:   8.2; xent: 2.1; lr: 0.00078; sents:  111236; bsz: 6205/7389/278; 28636/34098 tok/s;    541 sec;\n","[2023-12-01 10:49:56,445 INFO] Step 12900/20000; acc: 80.7; ppl:   8.1; xent: 2.1; lr: 0.00078; sents:  111758; bsz: 6226/7359/279; 49616/58644 tok/s;    591 sec;\n","[2023-12-01 10:51:26,905 INFO] Step 13000/20000; acc: 80.4; ppl:   8.2; xent: 2.1; lr: 0.00078; sents:  104723; bsz: 6062/7311/262; 26806/32328 tok/s;    681 sec;\n","[2023-12-01 10:51:28,560 INFO] valid stats calculation\n","                           took: 1.6532111167907715 s.\n","[2023-12-01 10:51:28,561 INFO] Train perplexity: 8.36661\n","[2023-12-01 10:51:28,561 INFO] Train accuracy: 79.6755\n","[2023-12-01 10:51:28,561 INFO] Sentences processed: 1.09333e+06\n","[2023-12-01 10:51:28,561 INFO] Average bsz: 6165/7340/273\n","[2023-12-01 10:51:28,561 INFO] Validation perplexity: 19.6658\n","[2023-12-01 10:51:28,561 INFO] Validation accuracy: 64.0816\n","[2023-12-01 10:51:28,561 INFO] Model is improving ppl: inf --> 19.6658.\n","[2023-12-01 10:51:28,562 INFO] Model is improving acc: -inf --> 64.0816.\n","[2023-12-01 10:51:28,589 INFO] Saving checkpoint models/model.enfrde_step_13000.pt\n","[2023-12-01 10:52:44,248 INFO] Step 13100/20000; acc: 80.1; ppl:   8.2; xent: 2.1; lr: 0.00077; sents:  110286; bsz: 6231/7344/276; 32223/37981 tok/s;    759 sec;\n","[2023-12-01 10:53:37,112 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=242)\n","\n","[2023-12-01 10:53:37,112 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 3\n","[2023-12-01 10:54:10,734 INFO] Step 13200/20000; acc: 80.0; ppl:   8.3; xent: 2.1; lr: 0.00077; sents:  109994; bsz: 6203/7368/275; 28689/34077 tok/s;    845 sec;\n","[2023-12-01 10:55:00,554 INFO] Step 13300/20000; acc: 80.6; ppl:   8.1; xent: 2.1; lr: 0.00077; sents:  107942; bsz: 6122/7282/270; 49156/58465 tok/s;    895 sec;\n","[2023-12-01 10:55:50,526 INFO] Step 13400/20000; acc: 80.2; ppl:   8.2; xent: 2.1; lr: 0.00076; sents:  109135; bsz: 6197/7343/273; 49602/58777 tok/s;    945 sec;\n","[2023-12-01 10:57:17,818 INFO] Step 13500/20000; acc: 80.8; ppl:   8.0; xent: 2.1; lr: 0.00076; sents:  111818; bsz: 6237/7425/280; 28580/34023 tok/s;   1032 sec;\n","[2023-12-01 10:58:08,193 INFO] Step 13600/20000; acc: 81.1; ppl:   8.0; xent: 2.1; lr: 0.00076; sents:  113032; bsz: 6177/7400/283; 49051/58758 tok/s;   1083 sec;\n","[2023-12-01 10:59:35,207 INFO] Step 13700/20000; acc: 81.1; ppl:   8.0; xent: 2.1; lr: 0.00076; sents:  106145; bsz: 6143/7264/265; 28239/33393 tok/s;   1170 sec;\n","[2023-12-01 11:00:25,658 INFO] Step 13800/20000; acc: 80.9; ppl:   8.1; xent: 2.1; lr: 0.00075; sents:  106877; bsz: 6204/7354/267; 49191/58308 tok/s;   1220 sec;\n","[2023-12-01 11:01:14,924 INFO] Step 13900/20000; acc: 80.5; ppl:   8.1; xent: 2.1; lr: 0.00075; sents:  108324; bsz: 6165/7326/271; 50054/59480 tok/s;   1269 sec;\n","[2023-12-01 11:01:26,329 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=248)\n","\n","[2023-12-01 11:01:26,330 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 4\n","[2023-12-01 11:02:38,184 INFO] Step 14000/20000; acc: 81.8; ppl:   7.8; xent: 2.1; lr: 0.00075; sents:  116856; bsz: 6188/7339/292; 29728/35258 tok/s;   1353 sec;\n","[2023-12-01 11:02:38,980 INFO] valid stats calculation\n","                           took: 0.7949354648590088 s.\n","[2023-12-01 11:02:38,981 INFO] Train perplexity: 8.2221\n","[2023-12-01 11:02:38,981 INFO] Train accuracy: 80.193\n","[2023-12-01 11:02:38,981 INFO] Sentences processed: 2.19374e+06\n","[2023-12-01 11:02:38,982 INFO] Average bsz: 6176/7342/274\n","[2023-12-01 11:02:38,982 INFO] Validation perplexity: 19.5813\n","[2023-12-01 11:02:38,982 INFO] Validation accuracy: 64.2835\n","[2023-12-01 11:02:38,982 INFO] Model is improving ppl: 19.6658 --> 19.5813.\n","[2023-12-01 11:02:38,982 INFO] Model is improving acc: 64.0816 --> 64.2835.\n","[2023-12-01 11:02:39,009 INFO] Saving checkpoint models/model.enfrde_step_14000.pt\n","[2023-12-01 11:03:46,131 INFO] Step 14100/20000; acc: 77.6; ppl:   8.8; xent: 2.2; lr: 0.00074; sents:  103018; bsz: 6170/7438/258; 36321/43789 tok/s;   1421 sec;\n","[2023-12-01 11:05:16,596 INFO] Step 14200/20000; acc: 77.9; ppl:   8.7; xent: 2.2; lr: 0.00074; sents:  105028; bsz: 6296/7351/263; 27839/32505 tok/s;   1511 sec;\n","[2023-12-01 11:06:06,013 INFO] Step 14300/20000; acc: 78.2; ppl:   8.6; xent: 2.2; lr: 0.00074; sents:  113137; bsz: 6107/7287/283; 49429/58982 tok/s;   1560 sec;\n","[2023-12-01 11:07:31,994 INFO] Step 14400/20000; acc: 78.1; ppl:   8.6; xent: 2.2; lr: 0.00074; sents:  111348; bsz: 6125/7355/278; 28495/34216 tok/s;   1646 sec;\n","[2023-12-01 11:08:21,390 INFO] Step 14500/20000; acc: 77.9; ppl:   8.7; xent: 2.2; lr: 0.00073; sents:  109044; bsz: 6191/7304/273; 50135/59145 tok/s;   1696 sec;\n","[2023-12-01 11:09:10,591 INFO] Step 14600/20000; acc: 77.7; ppl:   8.8; xent: 2.2; lr: 0.00073; sents:  108060; bsz: 6180/7380/270; 50247/59995 tok/s;   1745 sec;\n","[2023-12-01 11:09:26,640 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=248)\n","\n","[2023-12-01 11:09:26,640 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 5\n","[2023-12-01 11:10:36,291 INFO] Step 14700/20000; acc: 78.8; ppl:   8.4; xent: 2.1; lr: 0.00073; sents:  111975; bsz: 6113/7254/280; 28530/33856 tok/s;   1831 sec;\n","[2023-12-01 11:11:25,913 INFO] Step 14800/20000; acc: 79.3; ppl:   8.3; xent: 2.1; lr: 0.00073; sents:  111438; bsz: 6222/7341/279; 50155/59174 tok/s;   1880 sec;\n","[2023-12-01 11:12:49,441 INFO] Step 14900/20000; acc: 79.3; ppl:   8.3; xent: 2.1; lr: 0.00072; sents:  103691; bsz: 6145/7388/259; 29428/35379 tok/s;   1964 sec;\n","[2023-12-01 11:13:39,173 INFO] Step 15000/20000; acc: 79.6; ppl:   8.2; xent: 2.1; lr: 0.00072; sents:  108868; bsz: 6237/7425/272; 50165/59720 tok/s;   2014 sec;\n","[2023-12-01 11:13:39,946 INFO] valid stats calculation\n","                           took: 0.7717583179473877 s.\n","[2023-12-01 11:13:39,947 INFO] Train perplexity: 8.32857\n","[2023-12-01 11:13:39,947 INFO] Train accuracy: 79.6129\n","[2023-12-01 11:13:39,948 INFO] Sentences processed: 3.27935e+06\n","[2023-12-01 11:13:39,948 INFO] Average bsz: 6177/7345/273\n","[2023-12-01 11:13:39,948 INFO] Validation perplexity: 18.951\n","[2023-12-01 11:13:39,948 INFO] Validation accuracy: 64.6965\n","[2023-12-01 11:13:39,948 INFO] Model is improving ppl: 19.5813 --> 18.951.\n","[2023-12-01 11:13:39,948 INFO] Model is improving acc: 64.2835 --> 64.6965.\n","[2023-12-01 11:13:39,973 INFO] Saving checkpoint models/model.enfrde_step_15000.pt\n","[2023-12-01 11:14:47,035 INFO] Step 15100/20000; acc: 76.9; ppl:   9.0; xent: 2.2; lr: 0.00072; sents:  113022; bsz: 6144/7278/283; 36217/42899 tok/s;   2081 sec;\n","[2023-12-01 11:15:08,223 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=176)\n","\n","[2023-12-01 11:15:08,223 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 6\n","[2023-12-01 11:16:15,585 INFO] Step 15200/20000; acc: 77.5; ppl:   8.8; xent: 2.2; lr: 0.00072; sents:  105586; bsz: 6189/7292/264; 27959/32939 tok/s;   2170 sec;\n","[2023-12-01 11:17:04,896 INFO] Step 15300/20000; acc: 77.1; ppl:   8.9; xent: 2.2; lr: 0.00071; sents:  112311; bsz: 6184/7393/281; 50162/59969 tok/s;   2219 sec;\n","[2023-12-01 11:18:30,879 INFO] Step 15400/20000; acc: 77.8; ppl:   8.7; xent: 2.2; lr: 0.00071; sents:  106720; bsz: 6176/7357/267; 28730/34224 tok/s;   2305 sec;\n","[2023-12-01 11:19:20,775 INFO] Step 15500/20000; acc: 78.5; ppl:   8.5; xent: 2.1; lr: 0.00071; sents:  113374; bsz: 6075/7386/283; 48699/59213 tok/s;   2355 sec;\n","[2023-12-01 11:20:46,667 INFO] Step 15600/20000; acc: 78.2; ppl:   8.6; xent: 2.1; lr: 0.00071; sents:  106874; bsz: 6295/7356/267; 29316/34257 tok/s;   2441 sec;\n","[2023-12-01 11:21:36,368 INFO] Step 15700/20000; acc: 78.3; ppl:   8.5; xent: 2.1; lr: 0.00071; sents:  107946; bsz: 6162/7329/270; 49590/58985 tok/s;   2491 sec;\n","[2023-12-01 11:22:26,488 INFO] Step 15800/20000; acc: 78.0; ppl:   8.6; xent: 2.2; lr: 0.00070; sents:  113109; bsz: 6205/7324/283; 49525/58453 tok/s;   2541 sec;\n","[2023-12-01 11:22:50,137 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=242)\n","\n","[2023-12-01 11:22:50,138 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 7\n","[2023-12-01 11:23:52,096 INFO] Step 15900/20000; acc: 78.4; ppl:   8.5; xent: 2.1; lr: 0.00070; sents:  107053; bsz: 6139/7338/268; 28683/34288 tok/s;   2627 sec;\n","[2023-12-01 11:24:41,766 INFO] Step 16000/20000; acc: 78.4; ppl:   8.5; xent: 2.1; lr: 0.00070; sents:  111532; bsz: 6125/7304/279; 49327/58819 tok/s;   2676 sec;\n","[2023-12-01 11:24:42,820 INFO] valid stats calculation\n","                           took: 1.051257610321045 s.\n","[2023-12-01 11:24:42,822 INFO] Train perplexity: 8.41304\n","[2023-12-01 11:24:42,822 INFO] Train accuracy: 79.1891\n","[2023-12-01 11:24:42,822 INFO] Sentences processed: 4.37688e+06\n","[2023-12-01 11:24:42,822 INFO] Average bsz: 6175/7343/274\n","[2023-12-01 11:24:42,822 INFO] Validation perplexity: 18.7498\n","[2023-12-01 11:24:42,822 INFO] Validation accuracy: 64.8311\n","[2023-12-01 11:24:42,822 INFO] Model is improving ppl: 18.951 --> 18.7498.\n","[2023-12-01 11:24:42,822 INFO] Model is improving acc: 64.6965 --> 64.8311.\n","[2023-12-01 11:24:42,869 INFO] Saving checkpoint models/model.enfrde_step_16000.pt\n","[2023-12-01 11:26:39,000 INFO] Step 16100/20000; acc: 76.4; ppl:   9.1; xent: 2.2; lr: 0.00070; sents:  108136; bsz: 6188/7372/270; 21115/25152 tok/s;   2793 sec;\n","[2023-12-01 11:27:28,408 INFO] Step 16200/20000; acc: 77.2; ppl:   8.8; xent: 2.2; lr: 0.00069; sents:  107050; bsz: 6249/7318/268; 50590/59243 tok/s;   2843 sec;\n","[2023-12-01 11:28:18,385 INFO] Step 16300/20000; acc: 77.0; ppl:   8.9; xent: 2.2; lr: 0.00069; sents:  113317; bsz: 6128/7383/283; 49047/59088 tok/s;   2893 sec;\n","[2023-12-01 11:29:44,881 INFO] Step 16400/20000; acc: 77.0; ppl:   8.9; xent: 2.2; lr: 0.00069; sents:  107240; bsz: 6157/7292/268; 28471/33721 tok/s;   2979 sec;\n","[2023-12-01 11:30:34,406 INFO] Step 16500/20000; acc: 76.8; ppl:   8.9; xent: 2.2; lr: 0.00069; sents:  109512; bsz: 6244/7441/274; 50428/60100 tok/s;   3029 sec;\n","[2023-12-01 11:31:05,379 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=243)\n","\n","[2023-12-01 11:31:05,379 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 8\n","[2023-12-01 11:32:01,403 INFO] Step 16600/20000; acc: 77.1; ppl:   8.8; xent: 2.2; lr: 0.00069; sents:  114149; bsz: 6118/7303/285; 28131/33576 tok/s;   3116 sec;\n","[2023-12-01 11:32:51,088 INFO] Step 16700/20000; acc: 77.5; ppl:   8.7; xent: 2.2; lr: 0.00068; sents:  110831; bsz: 6150/7314/277; 49512/58881 tok/s;   3166 sec;\n","[2023-12-01 11:34:20,328 INFO] Step 16800/20000; acc: 77.4; ppl:   8.7; xent: 2.2; lr: 0.00068; sents:  104592; bsz: 6229/7378/261; 27919/33071 tok/s;   3255 sec;\n","[2023-12-01 11:35:09,835 INFO] Step 16900/20000; acc: 77.9; ppl:   8.6; xent: 2.2; lr: 0.00068; sents:  107797; bsz: 6182/7305/269; 49951/59024 tok/s;   3304 sec;\n","[2023-12-01 11:35:59,678 INFO] Step 17000/20000; acc: 77.6; ppl:   8.7; xent: 2.2; lr: 0.00068; sents:  110512; bsz: 6194/7347/276; 49710/58962 tok/s;   3354 sec;\n","[2023-12-01 11:36:00,482 INFO] valid stats calculation\n","                           took: 0.802239179611206 s.\n","[2023-12-01 11:36:00,483 INFO] Train perplexity: 8.49279\n","[2023-12-01 11:36:00,483 INFO] Train accuracy: 78.7891\n","[2023-12-01 11:36:00,483 INFO] Sentences processed: 5.47001e+06\n","[2023-12-01 11:36:00,483 INFO] Average bsz: 6177/7343/274\n","[2023-12-01 11:36:00,483 INFO] Validation perplexity: 18.0323\n","[2023-12-01 11:36:00,483 INFO] Validation accuracy: 65.1567\n","[2023-12-01 11:36:00,483 INFO] Model is improving ppl: 18.7498 --> 18.0323.\n","[2023-12-01 11:36:00,483 INFO] Model is improving acc: 64.8311 --> 65.1567.\n","[2023-12-01 11:36:00,509 INFO] Saving checkpoint models/model.enfrde_step_17000.pt\n","[2023-12-01 11:37:53,123 INFO] Step 17100/20000; acc: 77.6; ppl:   8.7; xent: 2.2; lr: 0.00068; sents:  109450; bsz: 6091/7304/274; 21475/25752 tok/s;   3468 sec;\n","[2023-12-01 11:38:42,429 INFO] Step 17200/20000; acc: 77.4; ppl:   8.8; xent: 2.2; lr: 0.00067; sents:  106625; bsz: 6131/7328/267; 49743/59452 tok/s;   3517 sec;\n","[2023-12-01 11:39:15,426 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=251)\n","\n","[2023-12-01 11:39:15,427 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 9\n","[2023-12-01 11:40:09,924 INFO] Step 17300/20000; acc: 77.6; ppl:   8.7; xent: 2.2; lr: 0.00067; sents:  111761; bsz: 6237/7403/279; 28513/33846 tok/s;   3604 sec;\n","[2023-12-01 11:40:59,775 INFO] Step 17400/20000; acc: 78.4; ppl:   8.4; xent: 2.1; lr: 0.00067; sents:  111230; bsz: 6105/7297/278; 48988/58550 tok/s;   3654 sec;\n","[2023-12-01 11:41:49,633 INFO] Step 17500/20000; acc: 78.1; ppl:   8.5; xent: 2.1; lr: 0.00067; sents:  108484; bsz: 6256/7387/271; 50193/59269 tok/s;   3704 sec;\n","[2023-12-01 11:43:16,133 INFO] Step 17600/20000; acc: 78.5; ppl:   8.4; xent: 2.1; lr: 0.00067; sents:  105434; bsz: 6110/7336/264; 28256/33925 tok/s;   3791 sec;\n","[2023-12-01 11:44:06,034 INFO] Step 17700/20000; acc: 78.2; ppl:   8.5; xent: 2.1; lr: 0.00066; sents:  108688; bsz: 6222/7312/272; 49876/58615 tok/s;   3840 sec;\n","[2023-12-01 11:44:44,696 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=177)\n","\n","[2023-12-01 11:44:44,697 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 10\n","[2023-12-01 11:45:31,791 INFO] Step 17800/20000; acc: 78.2; ppl:   8.5; xent: 2.1; lr: 0.00066; sents:  108509; bsz: 6146/7321/271; 28669/34149 tok/s;   3926 sec;\n","[2023-12-01 11:46:21,771 INFO] Step 17900/20000; acc: 78.0; ppl:   8.6; xent: 2.2; lr: 0.00066; sents:  113064; bsz: 6137/7355/283; 49114/58864 tok/s;   3976 sec;\n","[2023-12-01 11:47:53,169 INFO] Step 18000/20000; acc: 78.1; ppl:   8.5; xent: 2.1; lr: 0.00066; sents:  111182; bsz: 6261/7374/278; 27403/32271 tok/s;   4068 sec;\n","[2023-12-01 11:47:53,966 INFO] valid stats calculation\n","                           took: 0.7957041263580322 s.\n","[2023-12-01 11:47:53,968 INFO] Train perplexity: 8.50593\n","[2023-12-01 11:47:53,968 INFO] Train accuracy: 78.661\n","[2023-12-01 11:47:53,968 INFO] Sentences processed: 6.56444e+06\n","[2023-12-01 11:47:53,969 INFO] Average bsz: 6176/7343/274\n","[2023-12-01 11:47:53,969 INFO] Validation perplexity: 18.3648\n","[2023-12-01 11:47:53,969 INFO] Validation accuracy: 65.2641\n","[2023-12-01 11:47:53,969 INFO] Stalled patience: 3/4\n","[2023-12-01 11:47:54,014 INFO] Saving checkpoint models/model.enfrde_step_18000.pt\n","[2023-12-01 11:49:00,995 INFO] Step 18100/20000; acc: 79.1; ppl:   8.2; xent: 2.1; lr: 0.00066; sents:  107803; bsz: 6120/7354/270; 36094/43369 tok/s;   4135 sec;\n","[2023-12-01 11:49:51,081 INFO] Step 18200/20000; acc: 78.9; ppl:   8.3; xent: 2.1; lr: 0.00066; sents:  110186; bsz: 6207/7331/275; 49571/58545 tok/s;   4186 sec;\n","[2023-12-01 11:51:17,941 INFO] Step 18300/20000; acc: 78.9; ppl:   8.3; xent: 2.1; lr: 0.00065; sents:  106375; bsz: 6151/7345/266; 28327/33825 tok/s;   4272 sec;\n","[2023-12-01 11:52:08,329 INFO] Step 18400/20000; acc: 78.7; ppl:   8.4; xent: 2.1; lr: 0.00065; sents:  116941; bsz: 6271/7393/292; 49781/58690 tok/s;   4323 sec;\n","[2023-12-01 11:52:49,507 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=243)\n","\n","[2023-12-01 11:52:49,508 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 11\n","[2023-12-01 11:53:35,934 INFO] Step 18500/20000; acc: 78.7; ppl:   8.4; xent: 2.1; lr: 0.00065; sents:  108093; bsz: 6162/7300/270; 28136/33331 tok/s;   4410 sec;\n","[2023-12-01 11:54:25,705 INFO] Step 18600/20000; acc: 78.8; ppl:   8.3; xent: 2.1; lr: 0.00065; sents:  108551; bsz: 6124/7267/271; 49222/58406 tok/s;   4460 sec;\n","[2023-12-01 11:55:15,334 INFO] Step 18700/20000; acc: 78.7; ppl:   8.4; xent: 2.1; lr: 0.00065; sents:  106791; bsz: 6128/7341/267; 49393/59168 tok/s;   4510 sec;\n","[2023-12-01 11:56:46,601 INFO] Step 18800/20000; acc: 79.7; ppl:   8.1; xent: 2.1; lr: 0.00064; sents:  102708; bsz: 6190/7370/257; 27127/32303 tok/s;   4601 sec;\n","[2023-12-01 11:57:37,104 INFO] Step 18900/20000; acc: 79.3; ppl:   8.2; xent: 2.1; lr: 0.00064; sents:  117659; bsz: 6208/7386/294; 49170/58503 tok/s;   4652 sec;\n","[2023-12-01 11:59:04,628 INFO] Step 19000/20000; acc: 79.3; ppl:   8.2; xent: 2.1; lr: 0.00064; sents:  108735; bsz: 6177/7349/272; 28230/33588 tok/s;   4739 sec;\n","[2023-12-01 11:59:05,417 INFO] valid stats calculation\n","                           took: 0.7874636650085449 s.\n","[2023-12-01 11:59:05,419 INFO] Train perplexity: 8.4726\n","[2023-12-01 11:59:05,419 INFO] Train accuracy: 78.7111\n","[2023-12-01 11:59:05,419 INFO] Sentences processed: 7.65828e+06\n","[2023-12-01 11:59:05,419 INFO] Average bsz: 6175/7343/274\n","[2023-12-01 11:59:05,419 INFO] Validation perplexity: 18.2351\n","[2023-12-01 11:59:05,419 INFO] Validation accuracy: 65.2531\n","[2023-12-01 11:59:05,419 INFO] Stalled patience: 2/4\n","[2023-12-01 11:59:05,444 INFO] Saving checkpoint models/model.enfrde_step_19000.pt\n","[2023-12-01 12:00:14,741 INFO] Step 19100/20000; acc: 79.2; ppl:   8.2; xent: 2.1; lr: 0.00064; sents:  110663; bsz: 6165/7306/277; 35174/41681 tok/s;   4809 sec;\n","[2023-12-01 12:00:57,641 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=241)\n","\n","[2023-12-01 12:00:57,641 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 12\n","[2023-12-01 12:01:43,035 INFO] Step 19200/20000; acc: 79.2; ppl:   8.2; xent: 2.1; lr: 0.00064; sents:  106574; bsz: 6195/7375/266; 28065/33411 tok/s;   4897 sec;\n","[2023-12-01 12:02:33,101 INFO] Step 19300/20000; acc: 79.7; ppl:   8.1; xent: 2.1; lr: 0.00064; sents:  111195; bsz: 6165/7326/278; 49252/58535 tok/s;   4948 sec;\n","[2023-12-01 12:03:23,042 INFO] Step 19400/20000; acc: 79.4; ppl:   8.2; xent: 2.1; lr: 0.00063; sents:  110095; bsz: 6208/7395/275; 49721/59233 tok/s;   4998 sec;\n","[2023-12-01 12:04:49,588 INFO] Step 19500/20000; acc: 79.9; ppl:   8.0; xent: 2.1; lr: 0.00063; sents:  108613; bsz: 6179/7330/272; 28559/33877 tok/s;   5084 sec;\n","[2023-12-01 12:05:39,950 INFO] Step 19600/20000; acc: 79.7; ppl:   8.1; xent: 2.1; lr: 0.00063; sents:  112681; bsz: 6300/7378/282; 50038/58599 tok/s;   5134 sec;\n","[2023-12-01 12:07:05,158 INFO] Step 19700/20000; acc: 79.8; ppl:   8.1; xent: 2.1; lr: 0.00063; sents:  107132; bsz: 6121/7386/268; 28734/34672 tok/s;   5220 sec;\n","[2023-12-01 12:07:55,047 INFO] Step 19800/20000; acc: 79.7; ppl:   8.1; xent: 2.1; lr: 0.00063; sents:  106029; bsz: 6185/7351/265; 49594/58941 tok/s;   5270 sec;\n","[2023-12-01 12:08:45,490 INFO] * Transform statistics for corpus_1(100.00%):\n","\t\t\t* FilterTooLongStats(filtered=252)\n","\n","[2023-12-01 12:08:45,491 INFO] Weighted corpora loaded so far:\n","\t\t\t* corpus_1: 13\n","[2023-12-01 12:09:27,319 INFO] Step 19900/20000; acc: 79.3; ppl:   8.2; xent: 2.1; lr: 0.00063; sents:  112077; bsz: 6136/7287/280; 26598/31590 tok/s;   5362 sec;\n","[2023-12-01 12:10:17,083 INFO] Step 20000/20000; acc: 80.3; ppl:   7.9; xent: 2.1; lr: 0.00062; sents:  108699; bsz: 6107/7331/272; 49091/58926 tok/s;   5412 sec;\n","[2023-12-01 12:10:18,136 INFO] valid stats calculation\n","                           took: 1.051048994064331 s.\n","[2023-12-01 12:10:18,139 INFO] Train perplexity: 8.42565\n","[2023-12-01 12:10:18,139 INFO] Train accuracy: 78.8243\n","[2023-12-01 12:10:18,139 INFO] Sentences processed: 8.75204e+06\n","[2023-12-01 12:10:18,139 INFO] Average bsz: 6175/7344/274\n","[2023-12-01 12:10:18,139 INFO] Validation perplexity: 18.6137\n","[2023-12-01 12:10:18,139 INFO] Validation accuracy: 65.3259\n","[2023-12-01 12:10:18,139 INFO] Stalled patience: 1/4\n","[2023-12-01 12:10:18,188 INFO] Saving checkpoint models/model.enfrde_step_20000.pt\n"]}]},{"cell_type":"code","source":["!onmt_average_models -models /content/drive/MyDrive/nmt/models/model.enfrde_step_18000.pt /content/drive/MyDrive/nmt/models/model.enfrde_step_20000.pt -output /content/drive/MyDrive/nmt/models/model_avg.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TC9C_74iS-K2","executionInfo":{"status":"ok","timestamp":1701436043280,"user_tz":-420,"elapsed":25857,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}},"outputId":"c583b8ee-5d61-4569-de71-246c96549931"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-01 13:07:00.897398: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-01 13:07:00.897455: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-01 13:07:00.897498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-01 13:07:00.907958: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-01 13:07:02.194486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-12-01 13:07:04.357158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-01 13:07:04.357671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-01 13:07:04.357856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"]}]},{"cell_type":"markdown","metadata":{"id":"eShpS01j-Jcp"},"source":["# Translation\n","\n","Translation Options:\n","* `-model` - specify the last model checkpoint name; try testing the quality of multiple checkpoints\n","* `-src` - the subworded test dataset, source file\n","* `-output` - give any file name to the new translation output file\n","* `-gpu` - GPU ID, usually 0 if you have one GPU. Otherwise, it will translate on CPU, which would be slower.\n","* `-min_length` - [optional] to avoid empty translations\n","* `-verbose` - [optional] if you want to print translations\n","\n","Refer to [OpenNMT-py translation options](https://opennmt.net/OpenNMT-py/options/translate.html) for more details."]},{"cell_type":"code","metadata":{"id":"MbQEGTj4TybH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"94fb0336-59f8-4f3c-c66c-00ba3991313b","executionInfo":{"status":"ok","timestamp":1701526249954,"user_tz":-420,"elapsed":13057,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}}},"source":["# Translate the \"subworded\" source file of the test dataset\n","!onmt_translate -model model_avg.pt -src merged.source-filtered.source.subword.test -output test.translated -gpu 0 -min_length 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-02 14:10:42.991695: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-02 14:10:42.991753: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-02 14:10:42.991791: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-02 14:10:42.999895: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-02 14:10:44.290589: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-12-02 14:10:45.464835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-02 14:10:45.465350: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-02 14:10:45.465528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","[2023-12-02 14:10:46,804 INFO] Loading checkpoint from model.enfrde_step_20000.pt\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/onmt_translate\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/bin/translate.py\", line 67, in main\n","    translate(opt)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/bin/translate.py\", line 24, in translate\n","    translator = build_translator(opt, logger=logger, report_score=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/translate/translator.py\", line 34, in build_translator\n","    vocabs, model, model_opt = load_test_model(opt, device_id)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/model_builder.py\", line 93, in load_test_model\n","    checkpoint = load_checkpoint(model_path)\n","  File \"/usr/local/lib/python3.10/dist-packages/onmt/models/model_saver.py\", line 33, in load_checkpoint\n","    checkpoint = torch.load(ckpt_path, map_location=torch.device(\"cpu\"))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 986, in load\n","    with _open_file_like(f, 'rb') as opened_file:\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 435, in _open_file_like\n","    return _open_file(name_or_buffer, mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 416, in __init__\n","    super().__init__(open(name, mode))\n","FileNotFoundError: [Errno 2] No such file or directory: 'model.enfrde_step_20000.pt'\n"]}]},{"cell_type":"code","metadata":{"id":"XHYihrgfIrIO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d01d6161-c426-4eef-c80f-3f5d19d091cc","executionInfo":{"status":"ok","timestamp":1701436301357,"user_tz":-420,"elapsed":394,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}}},"source":["# Check the first 5 lines of the translation file\n","!head -n 5 test.translated"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["▁Sau ▁đó ▁chúng ▁tôi ▁hỏi , ▁\" Bạn ▁có ▁muốn ▁làm ▁một ▁cái ▁khác ▁với ▁ $ 2 , 7 0 ▁không ?\"\n","▁B ất ▁cứ ▁ai ▁cũng ▁có ▁thể ▁nhấn ▁vào ▁nút ▁\" refresh \" ▁liên ▁quan ▁đến ▁chức ▁năng ▁phổi , ▁và ▁nó ▁sẽ ▁đưa ▁bản ▁báo ▁cáo ▁của ▁tôi .\n","▁Có ▁thể ▁cô ▁ấy ▁ngồi ▁với ▁tôi ▁hàng ▁giờ ▁liền , ▁và ▁giơ ▁tay ▁lên ▁cho ▁tôi ▁xem ▁thế ▁giới ▁bị ▁nghèo ▁đói .\n","▁Vâng , ▁vâng , ▁đây ▁lại ▁là ▁một ▁điều ▁khó ▁khăn .\n","▁Điề u ▁này ▁dẫn ▁đến ▁một ▁tổ ▁tiên ▁duy ▁nhất ▁cách ▁đây ▁khoảng ▁ 2 0 , 0 0 0 ▁đến ▁ 2 5 , 0 0 0 ▁năm ?\n"]}]},{"cell_type":"code","metadata":{"id":"zRsJm6UET2C_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e6b4db3-1480-40d6-e36c-39e6bef285c5","executionInfo":{"status":"ok","timestamp":1701436321179,"user_tz":-420,"elapsed":7615,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}}},"source":["# If needed install/update sentencepiece\n","!pip3 install --upgrade -q sentencepiece\n","\n","# Desubword the translation file\n","!python3 MT-Preparation/subwording/3-desubword.py target.model test.translated"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Done desubwording! Output: test.translated.desubword\n"]}]},{"cell_type":"code","metadata":{"id":"ai4RhhGaKBp1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"180a7ae0-5af2-420e-aa3b-320613c9719e","executionInfo":{"status":"ok","timestamp":1701436322756,"user_tz":-420,"elapsed":4,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}}},"source":["# Check the first 5 lines of the desubworded translation file\n","!head -n 5 test.translated.desubword"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sau đó chúng tôi hỏi, \"Bạn có muốn làm một cái khác với $2,70 không?\"\n","Bất cứ ai cũng có thể nhấn vào nút \"refresh\" liên quan đến chức năng phổi, và nó sẽ đưa bản báo cáo của tôi.\n","Có thể cô ấy ngồi với tôi hàng giờ liền, và giơ tay lên cho tôi xem thế giới bị nghèo đói.\n","Vâng, vâng, đây lại là một điều khó khăn.\n","Điều này dẫn đến một tổ tiên duy nhất cách đây khoảng 20,000 đến 25,000 năm?\n"]}]},{"cell_type":"code","metadata":{"id":"kOUWB4r3OFOV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5859f232-735a-41a4-fe8e-d22472238ce1","executionInfo":{"status":"ok","timestamp":1701436330505,"user_tz":-420,"elapsed":1074,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}}},"source":["# Desubword the target file (reference) of the test dataset\n","!python3 MT-Preparation/subwording/3-desubword.py target.model merged.vi-filtered.vi.subword.test"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Done desubwording! Output: merged.vi-filtered.vi.subword.test.desubword\n"]}]},{"cell_type":"code","metadata":{"id":"0jULN0MwOFeH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"769b948a-a466-4d9c-ab91-9d06780c2549","executionInfo":{"status":"ok","timestamp":1701436333058,"user_tz":-420,"elapsed":3,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}}},"source":["# Check the first 5 lines of the desubworded reference\n","!head -n 5 merged.vi-filtered.vi.subword.test.desubword"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sau đó chúng tôi hỏi họ, \"Bạn có muốn lắp một cái khác với $2,70 không?\"\n","Vì vậy bất kỳ người dùng nào đều có thể đi vào đây và bấm vào \"báo cáo chức năng phổi\" và nó sẽ lấy những số liệu đó để cho ra bản báo cáo này mà tôi đã tạo ra.\n","Cô ngồi bên tôi hàng giờ đồng hồ, và mở mắt cho tôi về thế giới của đói nghèo.\n","Được rồi. Vâng, đây lại là một câu khó.\n","Phải chăng nó thực sự sẽ dẫn đến một ông tổ chung duy nhất nào đó sống cách đây khoảng vài 20 hay 25 nghìn năm?\n"]}]},{"cell_type":"markdown","metadata":{"id":"bHMumxqvLDDc"},"source":["# MT Evaluation\n","Evaluation using BLEU. Files must be detokenized/desubworded beforehand."]},{"cell_type":"code","metadata":{"id":"w-9XGYnaJ-Nj","executionInfo":{"status":"ok","timestamp":1701411677862,"user_tz":-420,"elapsed":412,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}},"outputId":"e51b5912-04bd-4b99-a884-91e15161067a","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Download the BLEU script\n","!wget https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-12-01 06:21:18--  https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 957 [text/plain]\n","Saving to: ‘compute-bleu.py’\n","\n","compute-bleu.py     100%[===================>]     957  --.-KB/s    in 0s      \n","\n","2023-12-01 06:21:18 (19.3 MB/s) - ‘compute-bleu.py’ saved [957/957]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"rYDG0x0KLk_O","executionInfo":{"status":"ok","timestamp":1701411688918,"user_tz":-420,"elapsed":5289,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}},"outputId":"59bc36a6-1615-49d4-a69d-3e46d235e573","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Install sacrebleu\n","!pip3 install sacrebleu"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.3.3)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n"]}]},{"cell_type":"code","metadata":{"id":"W3V3tZphTzK9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8449d0b3-b928-4b56-816a-0a00a8078f7a","executionInfo":{"status":"ok","timestamp":1701436338576,"user_tz":-420,"elapsed":968,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}}},"source":["# Evaluate the translation (without subwording)\n","!python3 compute-bleu.py test.translated.desubword merged.vi-filtered.vi.subword.test.desubword"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reference 1st sentence: Sau đó chúng tôi hỏi, \"Bạn có muốn làm một cái khác với $2,70 không?\"\n","MTed 1st sentence: Sau đó chúng tôi hỏi họ, \"Bạn có muốn lắp một cái khác với $2,70 không?\"\n","BLEU:  30.04134039264607\n"]}]},{"cell_type":"code","source":["!onmt_release_model --model \"/content/drive/MyDrive/nmt/models/model_avg.pt\" --output \"/content/drive/MyDrive/nmt/models/model_released.pt\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VLZ0Agg7gqC3","executionInfo":{"status":"ok","timestamp":1701436444856,"user_tz":-420,"elapsed":12580,"user":{"displayName":"Thinh Tran","userId":"05007552725679456088"}},"outputId":"dc1e766e-afd6-44fa-e90d-0084922960c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-01 13:13:55.878968: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-01 13:13:55.879020: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-01 13:13:55.879054: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-01 13:13:55.886703: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-01 13:13:57.338842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-12-01 13:13:59.230108: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-01 13:13:59.230552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-01 13:13:59.230712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"]}]}]}